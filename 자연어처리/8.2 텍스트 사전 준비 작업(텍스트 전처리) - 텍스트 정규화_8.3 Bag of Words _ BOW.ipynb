{"cells":[{"cell_type":"markdown","metadata":{"id":"FxSR3WjpHjYy"},"source":["## 8.2 텍스트 사전 준비 작업(텍스트 전처리) - 텍스트 정규화"]},{"cell_type":"markdown","metadata":{"id":"gQ7GKe6yHjYz"},"source":["### Text Tokenization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ExYlLrNHHjY0","outputId":"5c438b59-1e74-4913-babe-2b2b2ea3282b"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'list'> 3\n","['The Matrix is everywhere its all around us, here even in this room.', 'You can see it out your window or on your television.', 'You feel it when you go to work, or go to church or pay your taxes.']\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\yong\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["from nltk import sent_tokenize # 엔엘티케이(NLTK)는 자연어 처리를 위한 파이썬 패키지\n","import nltk\n","nltk.download('punkt')\n","\n","text_sample = 'The Matrix is everywhere its all around us, here even in this room. \\\n","               You can see it out your window or on your television. \\\n","               You feel it when you go to work, or go to church or pay your taxes.'\n","sentences = sent_tokenize(text=text_sample)\n","print(type(sentences),len(sentences))\n","print(sentences)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XZ-p44ngHjY1","outputId":"88c97a88-3cb5-454e-8146-1c6c8d14b01c"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'list'> 15\n","['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.']\n"]}],"source":["from nltk import word_tokenize\n","\n","sentence = \"The Matrix is everywhere its all around us, here even in this room.\"\n","words = word_tokenize(sentence)\n","print(type(words), len(words))\n","print(words)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ob_igrGiHjY1","outputId":"dac4ec62-6c35-46d5-8e96-48fd29d550b0"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'list'> 3\n","[['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.'], ['You', 'can', 'see', 'it', 'out', 'your', 'window', 'or', 'on', 'your', 'television', '.'], ['You', 'feel', 'it', 'when', 'you', 'go', 'to', 'work', ',', 'or', 'go', 'to', 'church', 'or', 'pay', 'your', 'taxes', '.']]\n"]}],"source":["from nltk import word_tokenize, sent_tokenize\n","\n","#여러개의 문장으로 된 입력 데이터를 문장별로 단어 토큰화 만드는 함수 생성\n","def tokenize_text(text):\n","\n","    # 문장별로 분리 토큰\n","    sentences = sent_tokenize(text)\n","    # 분리된 문장별 단어 토큰화\n","    word_tokens = [word_tokenize(sentence) for sentence in sentences]\n","    return word_tokens\n","\n","#여러 문장들에 대해 문장별 단어 토큰화 수행.\n","word_tokens = tokenize_text(text_sample)\n","print(type(word_tokens),len(word_tokens))\n","print(word_tokens)"]},{"cell_type":"markdown","metadata":{"id":"xwEM0uHsHjY1"},"source":["### Stopwords(불용어) 제거"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xoMwLBDjHjY1","outputId":"a2501671-0d08-4b93-cf45-fb59d4719c4e"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\yong\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KdLyK_n6HjY2","outputId":"ac800ef2-a9d9-43b1-da28-db9be7bd84b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["영어 stop words 갯수: 179\n","['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"]}],"source":["print('영어 stop words 갯수:',len(nltk.corpus.stopwords.words('english')))\n","print(nltk.corpus.stopwords.words('english')[:20])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vlKq0A-2HjY2","outputId":"8cb64d73-e3ef-42b7-cd51-0372612981c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["[['matrix', 'everywhere', 'around', 'us', ',', 'even', 'room', '.'], ['see', 'window', 'television', '.'], ['feel', 'go', 'work', ',', 'go', 'church', 'pay', 'taxes', '.']]\n"]}],"source":["import nltk\n","\n","stopwords = nltk.corpus.stopwords.words('english')\n","all_tokens = []\n","# 위 예제의 3개의 문장별로 얻은 word_tokens list 에 대해 stop word 제거 Loop\n","for sentence in word_tokens:\n","    filtered_words=[]\n","    # 개별 문장별로 tokenize된 sentence list에 대해 stop word 제거 Loop\n","    for word in sentence:\n","        #소문자로 모두 변환합니다.\n","        word = word.lower() # => 대문자로 변경 upper()\n","        # tokenize 된 개별 word가 stop words 들의 단어에 포함되지 않으면 word_tokens에 추가\n","        if word not in stopwords:\n","            filtered_words.append(word)\n","    all_tokens.append(filtered_words)\n","\n","print(all_tokens)"]},{"cell_type":"markdown","metadata":{"id":"uabovfL2HjY2"},"source":["### Stemming(어간 추출)과 Lemmatization(표제어 추출)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q_7joD-UHjY2","outputId":"e1717fda-329e-467f-e001-30776d50ce69"},"outputs":[{"name":"stdout","output_type":"stream","text":["work work work\n","amus amus amus\n","happy happiest\n","fant fanciest\n"]}],"source":["from nltk.stem import LancasterStemmer\n","stemmer = LancasterStemmer()\n","\n","print(stemmer.stem('working'),stemmer.stem('works'),stemmer.stem('worked'))\n","print(stemmer.stem('amusing'),stemmer.stem('amuses'),stemmer.stem('amused'))\n","print(stemmer.stem('happier'),stemmer.stem('happiest'))\n","print(stemmer.stem('fancier'),stemmer.stem('fanciest'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lGbe0C1PHjY3","outputId":"189c0854-8b91-4e7d-8f08-5c59b2984a2a"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\yong\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"name":"stdout","output_type":"stream","text":["amuse amuse amuse\n","happy happy\n","fancy fancy\n"]}],"source":["from nltk.stem import WordNetLemmatizer\n","import nltk\n","nltk.download('wordnet')\n","\n","lemma = WordNetLemmatizer()\n","print(lemma.lemmatize('amusing','v'),lemma.lemmatize('amuses','v'),lemma.lemmatize('amused','v'))\n","print(lemma.lemmatize('happier','a'),lemma.lemmatize('happiest','a'))\n","print(lemma.lemmatize('fancier','a'),lemma.lemmatize('fanciest','a'))"]},{"cell_type":"markdown","metadata":{"id":"iEOxfLv0HjY3"},"source":["## 8.3 Bag of Words – BOW"]},{"cell_type":"markdown","metadata":{"id":"fP56z2WGHjY3"},"source":["### 희소 행렬 - COO 형식"]},{"cell_type":"markdown","source":["COO(Coordinate: 좌표) 형식은 0이 아닌 데이터만 별도의 배열에 저장하고, 그 데이터가 가리키는 행과 열의 위치를 별도의 배열에 저장하는 방식"],"metadata":{"id":"E2Ahy5ZpOBGy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ZiDZ0zhHjY3"},"outputs":[],"source":["import numpy as np\n","\n","dense = np.array( [ [ 3, 0, 1 ], [0, 2, 0 ] ] )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r52PVGiyHjY3"},"outputs":[],"source":["from scipy import sparse\n","\n","# 0 이 아닌 데이터 추출\n","data = np.array([3,1,2])\n","\n","# 행 위치와 열 위치를 각각 array로 생성\n","row_pos = np.array([0,0,1])\n","col_pos = np.array([0,2,1])\n","\n","# sparse 패키지의 coo_matrix를 이용하여 COO 형식으로 희소 행렬 생성\n","sparse_coo = sparse.coo_matrix((data, (row_pos,col_pos)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G3EgamUmHjY3","outputId":"b3b2abc8-b2f2-425b-a330-98374ce77b80"},"outputs":[{"data":{"text/plain":["array([[3, 0, 1],\n","       [0, 2, 0]])"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["sparse_coo.toarray()"]},{"cell_type":"markdown","metadata":{"id":"U7zAgyQEHjY4"},"source":["### 희소 행렬 – CSR 형식"]},{"cell_type":"markdown","source":["\"CSR\"은 \"Compressed Sparse Row\"의 약자로, 희소 행렬을 효율적으로 표현하는 방식 중 하나입니다. 희소 행렬은 대부분의 원소가 0인 행렬을 의미하며, CSR 형식은 이러한 행렬을 효과적으로 메모리에 저장하기 위한 방법 중 하나"],"metadata":{"id":"a385gmssOCE5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5N1b5hO7HjY4","outputId":"2ee8d4a6-8023-427c-f8e4-48eac2eeba16"},"outputs":[{"name":"stdout","output_type":"stream","text":["COO 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인\n","[[0 0 1 0 0 5]\n"," [1 4 0 3 2 5]\n"," [0 6 0 3 0 0]\n"," [2 0 0 0 0 0]\n"," [0 0 0 7 0 8]\n"," [1 0 0 0 0 0]]\n","CSR 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인\n","[[0 0 1 0 0 5]\n"," [1 4 0 3 2 5]\n"," [0 6 0 3 0 0]\n"," [2 0 0 0 0 0]\n"," [0 0 0 7 0 8]\n"," [1 0 0 0 0 0]]\n"]}],"source":["from scipy import sparse\n","\n","dense2 = np.array([[0,0,1,0,0,5],\n","                  [1,4,0,3,2,5],\n","                  [0,6,0,3,0,0],\n","                  [2,0,0,0,0,0],\n","                  [0,0,0,7,0,8],\n","                  [1,0,0,0,0,0]])\n","\n","# 0 이 아닌 데이터 추출\n","data2 = np.array([1, 5, 1, 4, 3, 2, 5, 6, 3, 2, 7, 8, 1])\n","\n","# 행 위치와 열 위치를 각각 array로 생성\n","row_pos = np.array([0, 0, 1, 1, 1, 1, 1, 2, 2, 3, 4, 4, 5]) # 위치\n","col_pos = np.array([2, 5, 0, 1, 3, 4, 5, 1, 3, 0, 3, 5, 0]) # 위치\n","\n","# COO 형식으로 변환\n","sparse_coo = sparse.coo_matrix((data2, (row_pos,col_pos)))\n","\n","# 행 위치 배열의 고유한 값들의 시작 위치 인덱스를 배열로 생성\n","row_pos_ind = np.array([0, 2, 7, 9, 10, 12, 13])\n","\n","# CSR 형식으로 변환\n","sparse_csr = sparse.csr_matrix((data2, col_pos, row_pos_ind))\n","\n","print('COO 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인')\n","print(sparse_coo.toarray())\n","print('CSR 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인')\n","print(sparse_csr.toarray())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QX_bOnUWHjY4"},"outputs":[],"source":["dense3 = np.array([[0,0,1,0,0,5],\n","             [1,4,0,3,2,5],\n","             [0,6,0,3,0,0],\n","             [2,0,0,0,0,0],\n","             [0,0,0,7,0,8],\n","             [1,0,0,0,0,0]])\n","\n","coo = sparse.coo_matrix(dense3)\n","csr = sparse.csr_matrix(dense3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yMQRzxUDHjY4"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}